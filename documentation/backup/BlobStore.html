<h1>BlobStore Guide</h1>

<p>The BlobStore API is a portable means of managing key-value storage providers such as Microsoft Azure Blob Service
and Amazon S3. It offers both asynchronous and synchronous apis, as well as Map-based access to your data.
Our APIs are dramatically simplified from the providers, yet still offer enough sophistication to perform
most work in a portable manner.
We also have integrations underway for popular tools such as Apache commons VFS.</p>

<p>Like other components in <code>jclouds</code>, you always have means to gain access to the provider-specific interface
if you need functionality that is not available in our abstraction.</p>

<h2>Features</h2>

<h3>Location Aware API</h3>

<p>Our location API helps you to portably identify a container within context, such as Americas or Europe.</p>




<p>We use the same model across the [ComputeGuide ComputeService] which allows you to facilitate collocation of processing and data.</p>

<h3>Asynchronous API</h3>

<p>You have a choice of using either synchronous or asynchronous BlobStore API. If you choose to use the Asynchronous API,
you'll benefit by
gaining access to the most efficient means to achieve this, regardless of whether it is via threads, non-blocking io,
or native async clients such as google appengine's async url fetch service.</p>

<h3>Integration with non-java clients</h3>

<p>Using our <code>BlobRequestSigner</code>, you can portably generate HTTP requests that can be passed to external systems
for execution or processing.
Use cases include javascript side-loading and curl-based processing on the bash prompt.  Be creative!</p>

<h3>Transient Provider</h3>

<p>Our in-memory BlobStore allows you to test your storage code without credentials or a credit card!</p>

<h3>Filesystem Provider</h3>

<p>Our file system BlobStore allows you to use the same API when persisting to disk, memory, or a remote BlobStore like Amazon S3.</p>

<h2>Supported Providers</h2>

<p>All of the following providers can be used equally in any BlobStore API tool.</p>

<p>|| <em>provider</em> || <em>artifact</em> || <em>version</em> ||
|| transient || jclouds-blobstore || 1.0.0 ||                                                                                                                                           <br />
|| filesystem || jclouds-filesystem || 1.0.0 ||                                                                                                                                         <br />
|| eucalyptus-partnercloud-s3 || org.jclouds.provider/eucalyptus-partnercloud-s3 || 1.0.0 ||                                                                                            <br />
|| synaptic-storage || org.jclouds.provider/synaptic-storage || 1.0.0 ||                                                                                                                <br />
|| azureblob || org.jclouds.provider/azureblob || 1.0.0 ||                                                                                                                              <br />
|| cloudonestorage || org.jclouds.provider/cloudonestorage || 1.0.0 ||                                                                                                                  <br />
|| cloudfiles-us || org.jclouds.provider/cloudfiles-us || 1.0.0 ||                                                                                                                      <br />
|| cloudfiles-uk || org.jclouds.provider/cloudfiles-uk || 1.0.0 ||                                                                                                                      <br />
|| ninefold-storage || org.jclouds.provider/ninefold-storage || 1.0.0 ||                                                                                                                <br />
|| aws-s3 ||  org.jclouds.provider/aws-s3 || 1.0.0 ||                                                                                                                                   <br />
|| googlestorage || org.jclouds.provider/googlestorage || 1.0-SNAPSHOT ||                                                                                                               <br />
|| scaleup-storage || org.jclouds.provider/scaleup-storage || 1.0-SNAPSHOT ||                                                                                                           <br />
|| hosteurope-storage || org.jclouds.provider/scaleup-storage || 1.0-SNAPSHOT ||                                                                                                        <br />
|| tiscali-storage || org.jclouds.provider/scaleup-storage || 1.0-SNAPSHOT ||</p>

<p>You can also set the context property <code>provider</code>.endpoint to use the following APIs for your private cloud</p>

<p>|| <em>api</em> ||                                                                                                                                                                             <br />
||atmos||                                                                                                                                                                               <br />
||cloudfiles||                                                                                                                                                                          <br />
||filesystem||                                                                                                                                                                          <br />
||nova||                                                                                                                                                                                <br />
||swift||                                                                                                                                                                               <br />
||swift||                                                                                                                                                                               <br />
||walrus||</p>

<h2>Concepts</h2>

<p>The BlobStore API requires knowledge of 3 concepts: service, container, and blob.<br />
A BlobStore is a key-value store such as Amazon S3, where your account exists, and where you can create containers.<br />
A container is a namespace for your data, and you can have many of them.<br />
Inside your container, you store data as a Blob referenced by a name.  In all BlobStores the combination of your account, container,
and blob relates directly to an HTTPs url.</p>

<p>Here are some key points about blobstores:</p>

<ul><li>Globally addressable</li>
<li>Key, value with metadata</li>
<li>Accessed via HTTP</li>
<li>Containers are provisioned on demand through API calls</li>
<li>Unlimited scaling</li>
<li>Most are billed on a usage basis</li>
</ul><h3>Container</h3>

<p>A container is a namespace for your objects.  Depending on the service, the scope can be global, account, or sub-account scoped.<br />
For example, in Amazon S3, containers are called buckets, and they must be uniquely named such that no-one else in
 the world conflicts.  In other blobstores, the naming convention of the container is less strict.<br />
All blobstores allow you to list your containers and also the contents within them.  These contents can
either be blobs, folders, or virtual paths.</p>

<p>Everything in a BlobStore is stored in a container.  A container is like a website.  So, if my container name is adrian,
it will be created in an http accessible way.<br />
For example, if I'm using Amazon S3, a container looks like this: <code>http://adrian.s3.amazonaws.com</code>.<br />
If I store my photo with a key "mymug.jpg," you can guess it will end up here: <code>http://adrian.s3.amazonaws.com/mymug.jpg</code></p>

<h3>Blob</h3>

<p>A blob is unstructured data that is stored in a container.<br />
Some blobstores call them objects, blobs, or files.  You lookup blobs in a container by a text key, which often relates
directly to the HTTP url used to manipulate it.  Blobs can be zero length or larger, some restricting size to 5GB,
and others not restricting at all.</p>

<p>Finally, blobs can have metadata in the form of text key-value pairs you can store alongside the data.<br />
When a blob is in a folder, its name is relative to that folder.  Otherwise, it is its full path.</p>

<h3>Folder</h3>

<p>A folder is a subcontainer.  It can contain blobs or other folders.  The names of items in a folder are <code>basenames</code>.
Blob names incorporate folders via "/" - just like you would with a "regular" file system.</p>

<h3>Virtual Path</h3>

<p>A virtual path can either be a marker file or a prefix.  In either case, they are purely used to
give the appearance of a hierarchical structure in a flat BlobStore.<br />
When you perform a list at a virtual path, the blob names returned are absolute paths.</p>

<h3>Access Control</h3>

<p>By default, every item you put into a container is private, if you are interested in giving access to others,
you will have to explicitly configure that.</p>

<p>Currently, means to expose your containers to the public are provider-specific.</p>

<h3>limitations</h3>

<p>Each blobstore has its own limitations.</p>

<ul><li><em>S3</em> According to Amazon, it is better to create or delete buckets in a separate initialization or setup routine that you run less often.
You are also only allowed 100 buckets per account, so be parsimonious (frugal).</li>
<li><em>Azure</em> You have to wait 30 seconds before recreating a container with the same name.</li>
<li><em>Azure</em> currently supports max 64MB files, google storage has a very large limit,</li>
<li>Amazon S3 introduced a multipart upload possibility which allow files until 5TB size.</li>
<li><em>S3</em> and <em>Rackspace</em> CloudFiles have a 5GB limit.  We've engineered jclouds to not put further limits on blob size.</li>
</ul><h2>Using BlobStore API</h2>

<h3>Connecting to a BlobStore</h3>

<p>A connection to a <code>BlobStore</code> like S3 in jclouds is called a <code>BlobStoreContext</code>.<br />
An <code>BlobStoreContext</code> associates an identity on a provider to a set of network connections.
At a minimum, you need to specify your identity (in the case of S3, AWS Access Key ID) and a credential (in S3, your Secret Access Key).<br />
Once you have your credentials, connecting to your <code>BlobStore</code> service is easy:</p>

<pre><code>BlobStoreContext context = new BlobStoreContextFactory().createContext("aws-s3", identity, credential);</code></pre>

<p>This will give you a connection to the BlobStore, and if it is remote, it will be SSL unless unsupported by
the provider.  Everything you access from this context will use the same credentials and potentially the same objects.</p>

<h3>Disconnecting</h3>

<p>When you are finished with a context, you should close it using close method:</p>

<pre><code>context.close();</code></pre>




<p>There are many options available for creating contexts.  Please see the javadoc for
<a href="http://jclouds.rimuhosting.com/apidocs/org/jclouds/blobstore/BlobStoreContextFactory.html">BlobStoreContextFactory</a>
for detailed description.</p>

<h3>APIs</h3>

<p>You can choose from four apis in increasing complexity: Map, BlobMap, BlobStore, and AsyncBlobStore.<br />
For simple applications, you may find the most basic <code>Map&lt;String,InputStream&gt;</code> interface most appropriate.<br />
As complexity increases, you are also able to use the AsyncBlobStore interface: <code>FutureCommand</code>.  Let's review the <code>Map</code> apis first.</p>

<h4>InputStreamMap</h4>

<p>If you don't want to be bothered with the details of a BlobStore like Amazon S3, you may consider just accessing containers
 as a plain <code>Map&lt;String, InputStream&gt;</code> object.  Just create your context to to the BlobStore, choose the container of the stuff
 you want to manage, and get to work:</p>

<pre><code>BlobStoreContext context = new BlobStoreContextFactory().createContext("aws-s3", identity, credential);
Map&lt;String, InputStream&gt; map = context.createInputStreamMap("adrian.photos");
// do work
context.close();</code></pre>

<h5>Tips</h5>

<ul><li>Always close your InputStreams
When you do something like this, the <code>InputStream</code> returned may be holding a connection to the provider.<br />
Be sure to close your <code>InputStream</code> promptly.</li>
</ul><pre><code>InputStream aGreatMovie = map.get("theshining.mpg");
try {
      //watch
} finally {
if (aGreatMovie != null) aGreatMovie.close();
}
</code></pre>

<ul><li>Extra put methods
While you can feel free to use <code>map.put("stuff", new FileInputStream("stuff.txt")</code>, jclouds does provide some extra goodies.<br />
To use these, use the <code>InputStreamMap</code> class as opposed to <code>Map&lt;String,InputStream&gt;</code> when creating you Map view.</li>
</ul><pre><code>InputStreamMap map = context.createInputStreamMap("adrian.photos");
map.putFile("stuff", new File("stuff.txt"));
map.putBytes("secrets", Util.encrypt("secrets.txt"));
map.putString("index.html", "&lt;html&gt;&lt;body&gt;hello world&lt;/body&gt;&lt;/html&gt;");</code></pre>

<p>There are also corresponding <code>putAllFiles</code>, <code>Bytes</code>, <code>Strings</code> methods if you have bulk stuff to store.</p>

<h4>BlobMap</h4>

<p>There are some limitations when using the <code>Map&lt;String, InputStream&gt;</code> api.  For starters, you cannot pass any extra data
 to the provider.  For example, if you want to pass a default filename via the <code>Content-Disposition</code> group,
it cannot be done this way.  <code>BlobMap</code>  allows you do customize the data you are sending at the cost of coding to a <code>jclouds</code> API.
Considering it is only one class at this point, this is a decent tradeoff for many.</p>

<p>Here is an example that shows how to use the <code>BlobMap</code> api:</p>

<pre><code>BlobStoreContext context = new BlobStoreContextFactory().createContext("aws-s3", identity, credential);
BlobMap map = context.createBlobMap("adrian.photos");

Blob blob = map.blobBuilder("sushi.jpg")                                                                                                                                                  
               .payload(new File("sushi.jpg"))// or byte[]. InputStream, etc.                                                                                                             
               .contentDisposition("attachment; filename=sushi.jpg")                                                                                                                      
               .contentType("image/jpeg")                                                                                                                                                 
               .calculateMD5().build();

map.put(blob.getName(), blob);

context.close();</code></pre>

<h4>BlobStore (Synchronous)</h4>




<p>Here is an example of the <code>BlobStore</code> interface.</p>

<pre><code>// init
context = new BlobStoreContextFactory().createContext(
												"aws-s3",
                  								accesskeyid,
                  								secretaccesskey);
blobStore = context.getBlobStore();

// create container
blobStore.createContainerInLocation(null, "mycontainer");
  
// add blob
blob = blobStore.blobBuilder("test")  // you can use folders via newBlob(folderName + "/sushi.jpg")                                                                                     
                  .payload("testdata").build();
blobStore.putBlob(containerName, blob);</code></pre>

<h5>Creating a Container</h5>

<p>If you don't already have a container, you will need to create one.  First, get a BlobStore from your context:</p>

<pre><code>BlobStore blobstore = context.getBlobStore();</code></pre>

<p><code>Location</code> is a region, provider or another scope in which a container can be created to ensure data locality.
If you don't have a location concern, pass <code>null</code> to accept the default.</p>

<pre><code>boolean created = blobStore.createContainerInLocation(null, String container);
if (created){
	// the container didn't exist, but does now
}else{
 	// the container already existed
}
    </code></pre>

<h4>AsyncBlobStore</h4>

<p><code>AsyncBlobStore</code> is the third and most powerful way to interact with a BlobStore. The API are asynchronous even
if the engine you choose is not asynchronous.
<code>AsyncBlobStore</code> has the same methods as the <code>BlobStore</code>, but all commands return <code>java.util.concurrent.Future</code> results.<br />
Using <code>AsyncBlobStore</code> you can perform a lot of commands simultaneously, such as aggregating hundreds of blobs for processing.<br />
You can also attach listeners to the result, so that you can do things like publish to a message queue when an operation completes.</p>

<p>Here's an example of uploading tons of blobs at the same time:</p>

<pre><code>import static org.jclouds.concurrent.FutureIterables.awaitCompletion;

Map&lt;Blob, Future&lt;?&gt;&gt; responses = Maps.newHashMap();
for (Blob blob : blobs) {
   responses.put(blob, context.getAsyncBlobStore().putBlob(containerName, blob));
}
exceptions = awaitCompletion(responses, 
      context.utils().userExecutor(),
      maxTime,
      logger,
      String.format("putting into containerName: %s", containerName));</code></pre>

<h3>Multipart upload</h3>

<p>Providers may implement multipart upload for large or very files.                                                                                                                       <br />
Here's an example of <code>multipart upload</code> using aws-s3 provider, which <a href="http://docs.amazonwebservices.com/AmazonS3/latest/dev/index.html?qfacts.html">allow uploading files large as 5TB.</a></p>

<pre><code>import static org.jclouds.blobstore.options.PutOptions.Builder.multipart;                                                                                                                 

  // init                                                                                                                                                                                 
  context = new BlobStoreContextFactory().createContext(                                                                                                                                  
                  "aws-s3",                                                                                                                                                               
                  accesskeyid,                                                                                                                                                            
                  secretaccesskey);                                                                                                                                                       
  AsyncBlobStore blobStore = context.getAsyncBlobStore();                                                                                                                                 
                                                                                                                                                                                          
  // create container                                                                                                                                                                     
  blobStore.createContainerInLocation(null, "mycontainer");                                                                                                                               
                                                                                                                                                                                          
  File input = new File(fileName);                                                                                                                                                        
  // Add a Blob                                                                                                                                                                           
  Blob blob = blobStore.blobBuilder(objectName).payload(input)                                                                                                                            
               .contentType(MediaType.APPLICATION_OCTET_STREAM).contentDisposition(objectName).build();                                                                                   
  // Upload a file                                                                                                                                                                        
  ListenableFuture&lt;String&gt; futureETag = blobStore.putBlob(containerName, blob, multipart());                                                                                              
                                                                                                                                                                                          
  // asynchronously wait for the upload                                                                                                                                                   
  String eTag = futureETag.get();                                                                                                                                                         </code></pre>

<h3>Logging</h3>

<p>You can now see status of aggregate blobstore commands by enabling at least DEBUG on the log category: "jclouds.blobstore".</p>

<p>Here is example output:
</p><pre><code>2010-01-31 14:41:14,921 TRACE [jclouds.blobstore] (pool-4-thread-4) deleting from containerName: adriancole-blobstore2, 
completed: 5001/5001, errors: 0, rate: 14ms/op</code></pre>

<p>If you are using the Log4JLoggingModule, here is an example log4j.xml stanza you can use to enable blobstore logging:</p>

<pre><code> &lt;appender name="BLOBSTOREFILE" class="org.apache.log4j.DailyRollingFileAppender"&gt;
      &lt;param name="File" value="logs/jclouds-blobstore.log" /&gt;
      &lt;param name="Append" value="true" /&gt;
      &lt;param name="DatePattern" value="'.'yyyy-MM-dd" /&gt;
      &lt;param name="Threshold" value="TRACE" /&gt;
      &lt;layout class="org.apache.log4j.PatternLayout"&gt;
          &lt;param name="ConversionPattern" value="%d %-5p [%c] (%t) %m%n" /&gt;
      &lt;/layout&gt;
  &lt;/appender&gt;

  &lt;appender name="ASYNCBLOBSTORE" class="org.apache.log4j.AsyncAppender"&gt;
      &lt;appender-ref ref="BLOBSTOREFILE" /&gt;
  &lt;/appender&gt;

 &lt;category name="jclouds.blobstore"&gt;
      &lt;priority value="TRACE" /&gt;
      &lt;appender-ref ref="ASYNCBLOBSTORE" /&gt;
  &lt;/category&gt;</code></pre>

<h1>Clojure</h1>

<p>The above examples show how to use the <code>BlobStore</code> API in Java. You can also use the API in Clojure.</p>

<h2>Setup</h2>

<ul><li>Install <a href="http://github.com/technomancy/leiningen">leiningen</a></li>
<li><code>lein new mygroup/myproject</code></li>
<li><code>cd myproject</code></li>
<li><code>vi project.clj</code></li>
<li>for 1.0.0</li>
</ul><pre><code>(defproject mygroup/myproject "1.0.0" 
  :description "FIXME: write"
  :dependencies [[org.clojure/clojure "1.2.0"]
                 [org.clojure/clojure-contrib "1.2.0"]
				 [org.jclouds/jclouds-allblobstore "1.0.0"]])</code></pre>

<pre><code>* for snapshot
</code></pre>

<pre><code>(defproject mygroup/myproject "1.0.0" 
  :description "FIXME: write"
  :dependencies [[org.clojure/clojure "1.2.0"]
                 [org.clojure/clojure-contrib "1.2.0"]
                 [org.jclouds/jclouds-allblobstore "1.0.0"]]
  :repositories {"jclouds-snapshot" "https://oss.sonatype.org/content/repositories/snapshots"}) </code></pre>

<ul><li>Execute <code>lein deps</code></li>
</ul><h2>Usage</h2>

<p>Execute <code>lein repl</code> to get a repl, then paste the following or write your own code.<br />
Clearly, you need to substitute your accounts and keys below.</p>

<pre><code>(use 'org.jclouds.blobstore2)

(def *blobstore* (blobstore "azureblob" account encodedkey))                                                                                                                            
(create-container *blobstore* "mycontainer")                                                                                                                                            
(put-blob *blobstore* "mycontainer" (blob "test" :payload "testdata"))</code></pre>

<h1>Advanced Concepts</h1>

<p>This section covers advanced topics typically needed by developers of clouds.</p>

<h2>Signing requests</h2>

<h3>java example</h3>

<pre><code>
HttpRequest request = context.getSigner().
                              signGetBlob(&#x201C;adriansmovies&#x201D;,
                                          "sushi.avi");</code></pre>

<h3>clojure example</h3>

<pre><code>(let [request (sign-blob-request "adriansmovies"
                                 "sushi.avi" {:method :get})])
</code></pre>

<h2>Configure multipart upload strategies ==</h2>

<p>There are two <code>MultipartUploadStrategy</code> implementations: <code>SequentialMultipartUploadStrategy</code> and <code>ParallelMultipartUploadStrategy</code>.                                                     <br />
Default strategy is the <code>ParallelMultipartUploadStrategy</code>. With parallel strategy the number of threads running in parallel can be configured using <code>jclouds.mpu.parallel.degree</code> propert\
y, the default value is 4.</p>

<h1>Design</h1>




<h2>Marker Files</h2>

<p>Marker Files allow you to establish presence of directories in a flat key-value store.<br />
Azure, S3, and Rackspace all use pseudo-directories, but in a different ways.  For example, some tools look for a
content type "application/directory", while others look for naming patterns such as a trailing slash or the suffix <code>_$folder$</code>.</p>

<p>In jclouds, we attempt to detect whether a blob is pretending to be a directory, and if so, type it as StorageType.RELATIVE_PATH.<br />
Then, in a <code>list()</code> command, it will appear as a normal directory.   The two objects responsible for this
are <code>IfDirectoryReturnNameStrategy</code> and <code>MkdirStrategy</code>.</p>

<p>There is a problem with this approach, there are multiple ways to suggest presence of a directory.  For example, it is
entirely possible that both the trailing slash and _$folder$ suffixes exist.  For this reason, a simple remove,
or <code>rmDir</code> will not work, as may be the case that there are multiple tokens relating to the same directory.</p>

<p>For this reason, we have a <code>DeleteDirectoryStrategy</code> strategy.  The default version of this used
for flat trees removes all known deviations of directory markers.</p>

<h2>Content Metadata : Content Disposition</h2>

<p>You may be using jclouds to upload some phots to the cloud, show thumbnails of them to the user
via a website and allow to download the original image.  When the user clicks on the thumbnail,
a the download dialog appears.  To control the name of the file in the "save as" dialog,
you must set <a href="http://www.jtricks.com/bits/content_disposition.html">Content Disposition</a>.  Here's how you can do
it with BlobStore API:</p>

<pre><code>Blob blob = context.getBlobStore().blobBuilder("sushi.jpg")                                                                                                                               
               .payload(new File("sushi.jpg"))// or byte[]. InputStream, etc.                                                                                                             
               .contentDisposition("attachment; filename=sushi.jpg")                                                                                                                      
               .contentType("image/jpeg")                                                                                                                                                 
               .calculateMD5().build();</code></pre>

<h2>Large Lists</h2>

<p>A listing is a set of metadata about items in a container.  It is normally associated with a single GET request
against your container.</p>

<p>Large lists are those who exceed the default or maximum list size of the blob store.  In S3, Azure, and
Rackspace, this is 1000, 5000, and 10000 respectively.  Upon hitting this threshold, you need to continue the
list in another HTTP request.</p>

<p>In the new <code>BlobStore</code> api, list responses return a <code>PageSet</code> object.</p>

<p>A <code>PageSet</code> object is the same as a normal <code>Set</code>, except that it has a new method</p>

<pre><code>String getNextMarker();</code></pre>

<p>If this returns <code>null</code>, you have the entire listing.  If not, you can choose to continue iterating the list by
specifying the <code>ListContainerOption</code>
<code>afterMarker</code> to this value.</p>

<p>Our Map api knows how to concatenate lists via the <code>ListMetadataStrategy</code> object.</p>

<h2>Return Null on Not Found</h2>

<p>All apis, provider-specific or abstraction, must return null when an object is requested, but not found.<br />
Throwing exceptions is only appropriate when there is a state problem, for example requesting an object from a container
that does not exist is a state problem, and should throw an exception.</p>

<h2>Uploading Large Files</h2>

<p>As long as you use either <code>InputStream</code> or File as the payload your blob, you should be fine.<br />
Note that in S3, you must calculate the length ahead of time, since it doesn't support chunked encoding.
Our integration tests ensure that we don't rebuffer in memory on upload:
<a href="http://github.com/jclouds/jclouds/blob/master/core/src/test/java/org/jclouds/http/BaseHttpCommandExecutorServiceIntegrationTest.java">testUploadBigFile</a>.</p>

<p>This is verified against all of our http clients, conceding that it isn't going to help limited environments such as
google app engine.</p>

<h2>Downloading Large Files</h2>

<p>A blob you've downloaded via <code>blobstore.getBlob()</code> can be accessed via <code>blob.getPayload().getInput()</code> or
<code>blob.getPayload().writeTo(outputStream)</code>.  Since these are streaming, you shouldn't have a problem with memory
unless you rebuffer it.</p>

<p><code>Last Updated: 2011-07-26</code></p>